---
title: "Quickstart"
description: "This guide walks you through installing Agensight, capturing your first LLM trace, and setting up the MCP server to auto-extract agents, tools, and prompts from your codebase."
---

## Prerequisite

- Python ≥ 3.10

---

## Step 1: Install Agensight and Capture Your First Trace

Let’s start by installing the SDK and writing a small script to trace an OpenAI API call.

### 1. Create a virtual environment

```bash
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

### 2. Install Agensight

```bash
pip install agensight
```

### 3. Write your first trace

Create a file `my_llm_app.py`:

```python
from agensight import init, trace, span
import openai  # pip install openai

# Initialize Agensight
init(name="my-first-llm-project")

@trace("joke_generation_workflow")
def generate_a_joke():
    @span()
    def call_openai_for_joke():
        return openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": "Tell me a fun fact about programming"}]
        )

    print("Calling LLM to get a fun fact...")
    response = call_openai_for_joke()
    fun_fact = response.choices[0].message.content
    print(f"Fun Fact: {fun_fact}")
    return fun_fact

if __name__ == "__main__":
    generate_a_joke()
```

Make sure your `OPENAI_API_KEY` is set before running the script:

```bash
export OPENAI_API_KEY=your-key
python my_llm_app.py
```

---

## Step 2: View the Trace in Agensight

After running the script:

```bash
agensight view
```

This opens `http://localhost:5001`, where you can explore:

- Token usage
- Function spans
- Full LLM call trace

---

## Step 3: Set Up MCP Server with Cursor to Auto-Generate Config

To enable full tracing (agents, tools, prompts), you’ll need to generate an `agensight.config.json` for your project.

### 1. Clone and set up the MCP server

```bash
git clone git@github.com:PYPE-AI-MAIN/agensight_mcpserver.git
cd agensight_mcpserver

# Set up virtual environment
python -m venv mcp-env
source mcp-env/bin/activate  # On Windows: mcp-env\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Connect MCP server to Cursor

In `~/.cursor/mcp.json`, add:

```json
{
  "mcpServers": {
    "agensight-server": {
      "command": "/path/to/agensight_mcpserver/mcp-env/bin/python",
      "args": ["/path/to/agensight_mcpserver/server.py"],
      "description": "Tool to generate agensight config"
    }
  }
}
```

Replace the paths with the actual paths to your Python binary and `server.py` file.

### 3. Ask Cursor to generate config

In Cursor, open your project and ask:

```
Please analyze this codebase using the generateAgensightConfig MCP tool
```

Cursor will run the MCP server and create a valid `agensight.config.json` in your project root.

---

## What’s Next?

- Add more `@trace()` and `@span()` decorators to trace your pipelines in detail.
- Use the config file to enhance dashboard grouping for agents, tools, and prompts.
- Learn about advanced features in the [Core Concepts](./core-concepts/features-overview) guide.
