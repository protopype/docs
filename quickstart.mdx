---
title: "Quickstart: Your First Trace with Agensight"
description: "This guide will walk you through installing Agensight and capturing your first LLM trace."
---

## 1. Prerequisites

- **Python:** Agensight requires Python version 3.10 or higher. You can check your Python version by running:

  ```bash
  python --version
  ```

## 2. Installation

We highly recommend using a virtual environment for your project.

<Tabs>
  <Tab title="macOS / Linux">
    ```bash
    # Create a new virtual environment
    python3 -m venv .venv
    # Activate the virtual environment
    source .venv/bin/activate # On Windows: .venv\Scripts\activate
    ```
  </Tab>
</Tabs>

Once your virtual environment is activated, install Agensight using pip:

```bash
pip install agensight
```

## 3. Initialize Your Project & Run a Basic Trace

Let's write a simple Python script to trace an OpenAI API call.

Create a new Python file (e.g., `my_llm_app.py`) with the following code:

```python
# my_llm_app.py
from agensight import init, trace, span
import openai # Make sure you have the openai package installed: pip install openai

# 1. Initialize Agensight (Optional: provide a project name)
init(name="my-first-llm-project")

@trace("joke_generation_workflow") # Name your overall trace
def generate_a_joke():
    # Use @span() to mark specific operations within the trace
    @span()
    def call_openai_for_joke():
        # Ensure your OPENAI_API_KEY environment variable is set
        return openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": "Tell me a fun fact about programming"}]
        )

    print("Calling LLM to get a fun fact...")
    response = call_openai_for_joke()
    fun_fact = response.choices[0].message.content
    print(f"Fun Fact: {fun_fact}")
    return fun_fact

if __name__ == "__main__":
    generate_a_joke()
```

**Before running:**

- Ensure the `openai` Python package is installed: `pip install openai`
- Make sure your `OPENAI_API_KEY` environment variable is set with your OpenAI API key.

Now, run your script:

```bash
python my_llm_app.py
```

## 4. View Your Traces

After your script runs, Agensight will have captured the trace information locally. To view the traces in the Agensight dashboard, run the following command in your terminal:

```bash
agensight view
```

This will typically open the Agensight dashboard in your web browser at `http://localhost:5001`. You should see your "my-first-llm-project" and the "joke_generation_workflow" trace with the `call_openai_for_joke` span inside it.

## What's Next?

Congratulations\! You've successfully installed Agensight and captured your first LLM trace.

Here are some next steps you can take:

- **Explore the Dashboard:** Familiarize yourself with the Agensight UI and how it displays trace data, token counts, and other details.
- **Integrate with Existing Code:** Learn how to add `@trace` and `@span` decorators to your existing LLM application code.
- **Configure the Playground:** Check out how to set up and use the [Agensight Prompt Playground](./core-concepts/playground-setup).
- [**Dive into Core Concepts:**](./core-concepts/features-overview) Understand more about Agensight's features and how to leverage them.